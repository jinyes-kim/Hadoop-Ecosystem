# Hadoop
#### 하둡은 컴퓨터 클러스터를 구축하여 대규모 데이터 셋을 처리할 수 있는 프레임워크로 단일 클러스터에서 수 천대로 이루어진 클러스터까지 확장 가능하도록 설계되었다.
##### 베이스 아파치 하둡 프레임워크는 다음 모듈들을 포함한다.
- Hadoop Common
- HDFS (Hadoop Distribute File System)
- MapReduce
- Yarn (Yet Another Resource Negotiator)

## 1. Hadoop Common
##### Hadoop 모듈에 필요한 라이브러리와 유틸리티 모음

## 2. HDFS
##### HDFS는 대용량 파일을 블록으로 나눈다. 그리고 클러스터에 참여하고 있는 데이터 노드에 블록 조각들을 복제하고 중복해서 저장하여 데이터의 안정성을 확보한다. 
##### HDFS에는 네임 노드, 데이터 노드가 존재하며 하둡 클러스터에서 네임 노드 한 대는 파일 시스템을 관리하고 데이터 노드는 데이터 블록을 저장한다. 이때 블록의 기본 사이즈는 128MB이며 커스터마이징이 가능하다. 
##### 네임 노드는 지속해서 데이터 노드의 상태를 체크한다. 만약 데이터 노드의 응답이 끊어지면, 해당 노드에 저장되어 있던 데이터 블록들을 다른 데이터 노드에 복제한다. (이때 메타 데이터를 주키퍼가 관리하는지 다시 찾아보기)

## 3. MapReduce
##### 맵리듀스는 프로그래밍 모델로 블록으로 데이터를 나누어 저장하는 HDFS에서 대량의 데이터를 병렬로 처리할 수 있는 하둡의 핵심 요소다. Mapper와 Reduce로 구성되는데 Mapper는 여러개로 분리되어 있는 블록에 동일한 연산 및 처리 작업을 한다. Reduce는 연산이 완료된 결과물을 하나로 취합한다. 

## 4. Yarn
##### 빅데이터 어플리케이션을 위한 대규모 분산 운영체제로 클러스터 관리를 위해 설계되었다. Yarn은 맵리듀스뿐만 아니라 다양한 분산 프로그램들이 하둡 클러스터에 저장된 데이터를 처리할 수 있게 해준다. 하둡 1세대 MapReduce의 리소스 관리 및 스케줄링 기능을 대체한다.

---
## 하둡과 전통적인 데이터베이스의 차이점
##### 데이터베이스는 상대적으로 적은 양의 데이터를 지속적으로 변경하는 경우에 적합하며 하둡은 전체 데이터셋을 분석할 때 적합하다. 
