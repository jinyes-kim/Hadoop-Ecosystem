> Hadoop: The Definitive Guide
# 0. Hadoop
하둡은 컴퓨터 클러스터를 구축하여 대규모 데이터 셋을 처리할 수 있는 프레임워크이다. 단일 서버에서 수천 대의 머신으로 이루어진 클러스터로 확장 가능하도록 설계되었다.
관계형 데이터베이스와의 가장 큰 차이점은 관계형 데이터베이스의 경우 상대적으로 적은 양의 데이터를 낮은 지연 시간에 처리하기 위해 데이터셋을 인덱싱하기 때문에 지속적으로 변경되는 데이터셋에 적합하다. 반면 하둡은 데이터를 한 번 저장하고 여러번 읽는 어플리케이션에 적합하다.


베이스 아파치 하둡 프레임워크는 아래 모듈을 포함한다.
- Hadoop Common
- HDFS(Hadoop Distributed File System)
- MapReduce
- YARN (Yet Another Resource Negotiator)
---
# 1. 구성 요소
## 1.1 Hadoop Common
하둡 모듈에 필요한 라이브러리와 유틸리티 모음이다.

## 1.2 HDFS
HDFS는 대용량 파일을 블록으로 나누어 클러스터에 참여하고 있는 여러 대의 노드에 저장한다. 즉 데이터를 여러 서버에 중복해서 저장함으로써 데이터의 안정성을 확보한다. 

![hdfsarchitecture](https://user-images.githubusercontent.com/54028026/128013505-02101d5b-a460-4e21-903e-152b68efb257.gif)
> [https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html](https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html)

블록의 디폴트 사이즈는 128MB이며 수정이 가능하다. 일반 디스크에서의 블록과 하둡의 데이터 블록의 가장 큰 차이점은 하드디스크에서 블록의 사이즈가 16KB이고 데이터가 2KB라면 남는 공간을 낭비하지만, 하둡의 경우 1MB 데이터를 저장한다고 블록의 남은 127MB를 낭비하지는 않는다. 단 데이터 블록의 개수가 많아질수록 읽기 작업에서 손해를 보게된다.

하둡 클러스터에는 네임노드와 데이터노드가 존재한다. 
- 네임노드는 모든 파일시스템의 네임스페이스를 관리한다. 파일시스템 트리와 그 트리에 포함된 모든 파일과 디렉터리에 대한 메타데이터를 유지한다. 해당 정보는 네임스페이스 이미지와 eidt log라는 두 종류의 파일로 로컬 디스크에 영속적으로 저장된다. 또한 네임노드는 파일에 속한 모든 블록이 어느 데이터노드에 저장되어 있는지 파악하고 지속적으로 업데이트한다. 따라서 네임노드에 문제가 생기면 파일시스템이 동작하지 않는다. 이를 위해 하둡은 두 가지 메커니즘을 제공하며 첫 번째가 파일시스템의 메타데이터를 지속적인 상태로 보존하기 위해 파일로 백업하며, 두 번째로 세컨더리 네임노드를 운영한다.

- 데이터노드는 클라이언트나 네임노드의 요청이 있을 때 블록을 저장하거나 탐색한다. 저장하고 있는 블록의 목록을 주기적으로 네임 노드에 보고한다.

## 1.3 MapReduce
맵리듀스는 데이터 처리를 위한 프로그래밍 모델이다. 맵 단계와 리듀스 단계로 구성되어 있으며 맵 단계에서는 흩어져 있는 데이터 블록에 동일한 작업을 수행한다. 그리고 그 결과물을 리듀스 단계에서 취합한다. 

## 1.4 YARN
YARN은 클러스터에서 컴퓨팅 리소스를 관리하는 플랫폼이다. 클러스터의 자원을 요청하고 사용하기 위한 API를 제공하며 사용자는 YARN에 내장된 분산 컴퓨팅 프레임워크에서 고수준 API를 작성해서 사용할 수 있다. 

맵리듀스, 스파크 등과 같은 분산 컴퓨팅 프레임워크는 클러스터 계산 계층(YARN)과 클러스터 저장 계층(HDFS, Hbase)위에서 YARN 어플리케이션을 실행한다.

리소스 매니저와 노드 매니저가 존재하며 리소스 매니저는 전체 클러스터의 자원 사용량을 관리하고, 노드 매니저는 컨테이너를 구동하고 모니터링하는 역할믈 맡는다.

스케줄링 옵션으로 FIFO, Capacity, Fair 를 제공한다. FIFO는 요청된 순서대로 어플리케이션의 요청을 처리한다. Capacity 스케줄러는 지정된 가용량을 미리 할당하는 방식이다. Fair 스케줄러는 실행 중인 모든 어플리케이션에 동일하게 자원을 할당한다. 

---
# 2. 운영 및 관리
## HDFS 블록크기
HDFS의 기본 블록크기는 128MB인데, 더 큰 블록 크기를 사용하면 네임노드의 메모리 부담을 줄이면서 매퍼가 더 많은 데이터를 처리할 수 있다. 

## 예약된 저장 공간
기본적으로 데이터노드는 사용가능한 모든 공간을 사용한다. 따라서 저장장치의 볼륨을 남겨두고 싶다면 dfs.datanode.du.reserved 속성을 이용해서 남기고 싶은 만큼 용량을 지정해야한다.

## 휴지통
HDFS는 휴지통 기능이 있어서 삭제된 파일은 trash 디렉터리로 이동한다. core-site.xml 설정 파일에서 fs.trash.interval 속성으로 설정하며, 기본 옵션은 0으로 비활성화되어 있다.

## 잡 스케줄러
다중 사용자 지원을 위한 잡 스케줄링을 지원하며 해당 설정은 YARN을 통해 변경 가능하다.

## 슬로우 리듀스
디폴트 설정의 스케줄러는 잡에서 맵 단계가 5%까지 완료되었다가 리듀스 단계를 실행한다. 규모가 큰 잡에서는 문제가 발생할 수 있으므로 mapreduce.job.reduce.slowstart.completedmaps 속성을 큰 값으로 설정하여 ex) 0.8(80%) 해당 문제를 유연하게 대처할 수 있다.

## 단락 지역 읽기
HDFS에서 파일을 읽을 때 클라이언트는 데이터노드와 교신하며 TCP 연결을 통해 클라이언트로 데이터를 전송한다. 이때 읽어야하는 블록이 클라이언트와 동일한 노드에 있다면 네트워크를 거치지 않고 디스크에서 직접 해당 블록에 접근하는 것이 더 효율적이다. 이를 short-circuit local read라고 하며, 이를 사용하면 Hbase 같은 어플리케이션의 성능이 향상된다. dfs.client.read.shortcircuit 속성을 true로 설정하면 사용할 수 있다.

## 벤치마크
하둡은 벤치마크 기능을 포함하고 있으며 doc/share/lib-example 디렉터리에 위치한 text.jar 파일로 실행해볼 수 있다.

## dfsadmin
dfsadmin 명령어로 HDFS의 상태 정보를 확인하고 다양한 작업을 수행할 수 있다. ex) 네임노드의 파일시스템 이미지 백업 -> hdfs dfsadmin -fetchimage fsimage.backup, 데이터노드 갱신 hdfs dfsadmin -refreshNodes

## 파일 시스템 점검
hdfs fsck / 명령어로 fsck 유틸리를 실행하여 파일시스템의 상태를 체크할 수 있다. 

## 데이터노드 블록 스캐너
모든 데이터노드는 주기적으로 블록 스캐너를 실행하여 저장되어 있는 블록들을 주기적으로 검사한다. dfs.datanode.scan.period.hours 속성을 이용해서 스캔 주기를 조절할 수 있다. 기본 설정은 504시간(3주)이다. 

## 밸런서
sbin 디렉터리의 start-.balancer.sh 파일은 밸런서 프로그램으로 데이터노드의 블록을 사용률이 낮은 데이터노드로 옮기는 하둡 데몬이다. 밸런서는 클러스터가 균형 상태가 될때까지 블록을 이동시킨다. 

## 노드 제거
노드를 하둡 클러스터에서 제거하는 방법은 exclude 파일로 제어한다. HDFS는 dfs.hosts.exclude 속성에, YARN은 yarn.resourcemanager.nodes.exclude-path 속성에 제거할 노드를 설정한다. 설정 후 hdfs dfsadmin - refreshNodes 명령어로 갱신한다. 

---
# 3. Cheat Sheet
> https://linoxide.com/hadoop-commands-cheat-sheet/

![hadoop-hdfs-commands-cheatsheet-900x1500](https://user-images.githubusercontent.com/54028026/128471863-0f86f889-b75e-4801-9c8a-a0a8e24fb2a0.png)
---
--- 
